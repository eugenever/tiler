# Тайлирование векторных данных

За основу кодирования векторных данных принята концепция [Mapbox Vector Tile Specification](https://github.com/mapbox/vector-tile-spec), а именно её редакция `версии 2.1`.
Указанная спецификация реализована в следующих зависимостях текущего проекта ГеоСервера (Tiler-Server):

- расширения `PostGIS` для `PostgreSQL`
- питоновской библиотеки [mapbox-vector-tile](https://github.com/tilezen/mapbox-vector-tile)
- растовских библиотек [t-rex-core](https://gitlab.isone.com/aspect/aspect-gis/-/tree/develop/Tiler-Rust/server/rust/t-rex-core?ref_type=heads) и [mvt](https://gitlab.isone.com/aspect/aspect-gis/-/tree/develop/Tiler-Rust/server/rust/mvt?ref_type=heads)

Библиотеки Python'а и Rust'а проверены на предмет сходимости результатов кодирования и декодирования, где образцом
выступали векторные тайлы полученные от сервиса `MapTiler`. Образцы и результаты перекодирования (файлы с суффиксом
`_reencode`) находятся в папке [server/rust/t-rex-core/data/tiles](https://gitlab.isone.com/aspect/aspect-gis/-/tree/develop/Tiler-Rust/server/rust/t-rex-core/data/tiles?ref_type=heads).

По итогу опытов было отмечено, что для создания своих (оффлайн) карт необходимо использовать СУБД, которая бы позволяла
`одновременно` хранить данные геометрий и создавать на их основе векторные тайлы. Фактически, это безальтернативное
использование `PostgreSQL (PostGIS)` или `DuckDB` (при условии, что будет реализован функционал запрошенный разработчиком
rio-tiler'а - ST_AsMVT, ST_AsMVTGeom, ST_Segmentize, ST_MakeEnvelope). Главная причина подобного решения в том, что необходимо
выполнять сериализацию геометрий получаемых из БД в целевом языке программирования с последующей геообработкой. Это
несёт в себе большие затраты по времени и памяти, в том числе в рамках Rust. Данный подход позволяет заранее на стадии
препроцессинга подготовить оптимизированные представления геоданных в разрезе зумов чтобы избежать большого объёма
геометрий в тайлах и тем самым обеспечить быстрый рендер на UI. Для структурирования данных существуют отдельные проекты,
которые представляют собой, по большому счету, оптимизированную структуру таблиц, описывающих слои тайла. Примером
такого проекта может служить [Apache Baremaps](https://baremaps.apache.org/)

## Обработка пользовательских геоданных

Для хранения геоданных целесообразно использовать СУБД `PostgreSQL`. При этом существует опыт применения в ряде сценариев
отдельных файлов `SQLite` или `DuckDB` под каждый индентификатор устройства. Но последние варианты не имеют возможности
генерировать Mapbox Vector Tiles.

В качестве расширения обеспечивающего производительные `SELECT` и `INSERT` операции, а также вцелом хранение и управление
временными сериями предлагается использовать `TimescaleDB`. В зависимости от объемов данных трекинга необходимо правильно
подобрать размер партиции (1 час, 1 день, 7 дней и т.д.).
Для базовой таблицы точек трекинга не использовать геопространственный индекс `PostGIS` (GIST, SPGIST). Это связано с тем,
что для фильтрации будут применяться поля `timestamp` и условный `device_id`, которые в свою очередь индексируются
дефолтным `b-tree` индексом `PostgreSQL`. Индексацию геометрий точек на указанной таблице выполнять через `b-tree` индекс
по значениям `ST_X` и `ST_Y`. Выгоднее использовать составной индекс по значениям: `device_id`, `timestamp`, `ST_X` и `ST_Y`.

Вставку новых точек в таблицу трекинга выгоднее выполнять параллельными бэтчами по 500-1000 точек за раз. То есть
создаем пул подключений к `PostgreSQL` с числом конекшенов 10 и за раз вставляем, например, по 10\*500 точек.

Для отображения текущего (последнего) положения всех устройств выгодно создать материализованное представление и
обновлять его с каким-то временным шагом (например, 1 мин). Указанное обновление выполнять средствами планировщика
работ расширения `TimescaleDB`.

Для отображения треков (LineString) на карте существует практика мерджа точек из базовой таблицы трекинга в `LineString`
посредством стандартного функционала `PostGIS` - `ST_MakeLine`. Указанную агрегацию неэффективно реализовывать в рамках
языка `PLPGSQL` из-за его ограничений по однопроцессности и невозможности полноценно обрабатывать паники/эксепшены.
Указанный функционал эффективнее реализовать на стороне `Rust`, но с ядром на геозапросах `PostGIS`. Временной интервал,
на основе которого точки будут агрегироваться в линии необходимо подобрать опытным путем, например, 5 мин, 10 мин.

Для удаления старых данных (партиций) использовать функционал расширения `TimescaleDB`

## Оптимизация настроек PostgreSQL

Рекомендуемые версии программного обеспечения:

- PostgreSQL 16.x
- PostGIS 3.4

Указанные версии ПО обеспечивают хороший уровень производительности и усовершенствованные/улучшенные геофункции.
Дополнительно также необходимо установить расширение `hstore`.

Параметры настроек PostgreSQL (оригинальный файл конфигирации PostgreSQL):

- max_connections: максимальное число подключений, по умолчанию 100, переопределить под реальные потребности
- shared_buffers = 1GB
- work_mem = 512MB
- maintenance_work_mem = 2047MB
- temp_file_limit = 25GB
- max_worker_processes = 47 максимальное число воркеров. Данный параметр согласовать с числом воркеров приложения геосервера,
  он же Tiler-Server, которые будут выполнять тайлинг растров (запуск NumPy + Numba). В сумме два эти параметра не должны
  превышать доступное число ядер. Также можно оценить степень нагрузки при тайлинге векторных и растровых данных, чтобы
  сместить пропорции числа ядер для растров и векторов.
- max_parallel_workers_per_gather = 14
- max_parallel_maintenance_workers = 4
- max_parallel_workers = 28 количество воркеров из числа `max_worker_processes` которые могут использоваться при параллельных
  операциях (не более `max_worker_processes`)
- checkpoint_timeout = 60min
- max_wal_size = 10GB
- min_wal_size = 5GB
- effective_cache_size = 12287MB
- shared_preload_libraries = 'postgis-3,timescaledb'
- timescaledb.max_background_workers = 16
